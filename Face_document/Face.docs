Face Recognition with FaceNet and MTCNN we are using face recognition app five methods
https://arsfutura.com/magazine/face-recognition-with-facenet-and-mtcnn/

Face recognition

Arc face

Dlip

Face net 

Deep face

 

1.Face Recognition

First you create a folder for employee name

inside a folder five images for employer

then you create a pickle file

create pickle file code


import cv2
import face_recognition
import os
import datetime
import numpy as np
import pickle

directory = "face_data" #emloyee name folder 
face = []
name = []

for path, subdirnames, filenames in os.walk(directory):
    for filename in filenames:
        img_path = os.path.join(path, filename)
        img = cv2.imread(img_path)
        resized = cv2.resize(img, (640,480), interpolation=cv2.INTER_AREA)
        cv2.imwrite("sample.jpg",resized)
        id = os.path.basename(path)
        known_image = face_recognition.load_image_file("sample.jpg")
        biden_encoding = face_recognition.face_encodings(known_image)[0]
        face.append(biden_encoding)
        name.append(id)
print(name)
print("[INFO] serializing encodings...")
data = {"encodings": face, "names": name}
f = open("emp1717.pickle", "wb")
f.write(pickle.dumps(data))
f.close()
Recognise a Face code


import cv2
import face_recognition
import os
import numpy as np
import pickle

data = pickle.loads(open("emp1717.pickle", "rb").read()) # load a pickle file
img = cv2.imread("face_data/Moorthy/17170.jpg")  #It is a test file
facesCurFrame = face_recognition.face_locations(img)
encodesCurFrame = face_recognition.face_encodings(img, facesCurFrame)
for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):
    faceDis = face_recognition.face_distance(data["encodings"], encodeFace)
    acc = np.array(faceDis)
    matchIndex = np.min(acc)
    name_data =np.argmin(faceDis)
    print(matchIndex)
    if matchIndex < 0.49:
        val = data["names"]
        n = val[name_data]
        print(" is this "+n)
 

2.Arc Face

First you create a folder for employee name

inside a folder five images for employer

then you create a npy file

 

Create npy file python code


from arcface import ArcFace
import numpy as np
import os
import cv2
import tables
from npy_append_array import NpyAppendArray

face_rec = ArcFace.ArcFace()
direct = "images"
faces = []
name = []
for dir in os.listdir(direct):
    for filename in os.listdir(os.path.join(direct, dir)):
        img_path = os.path.join(direct, dir, filename)
        emb1 = face_rec.calc_emb(img_path)
        faces.append(emb1)
        name.append(dir)

Embeddings = np.array(faces)
Names = np.array(name)
np.save("embed.npy",Embeddings)
np.save("name.npy",Names)
encode= np.load('embed.npy')
name = np.load('name.npy')
print(len(encode))
print(len(name))
Recognise the face code


from arcface import ArcFace
import numpy as np
import os
import cv2

face_rec = ArcFace.ArcFace()

img = "Moorthy/Moorthy1.png"emb2 = face_rec.calc_emb(img)
# print(emb2)encode= np.load('embed.npy')
name = np.load('name.npy')
test = []
for x in encode:
    a = face_rec.get_distance_embeddings(x, emb2)
    test.append(a)
com = dict(zip(test, name))
order = sorted(com.items(), key=lambda d: d[0])
result = min(order)
print(result)
if result[0] <= 0.60:
    # print(result)    name = result[1]
    print(name)
 

3 .Dlip 

download the face detect dlip models

1.shape_predictor_68_face_landmarks.dat

2.dlib_face_recognition_resnet_model_v1.dat

create folder in employee name inside images

like that 

Data

Moorthy

img1.jpg

img2.jpg

**important note :- Image should be full face not in cropped face

create pickle model python code


import json
import os
import uuid
import cv2
import dlib
import numpy as np

predictor_path = "models/shape_predictor_68_face_landmarks.dat"face_rec_model_path = "models/dlib_face_recognition_resnet_model_v1.dat"detectors = dlib.get_frontal_face_detector()
sp = dlib.shape_predictor(predictor_path)

facerec = dlib.face_recognition_model_v1(face_rec_model_path)
directory = "data"encode = []
name = []

for dir in os.listdir(directory):
    for filename in os.listdir(os.path.join(directory,dir)):
        img_path = os.path.join(directory, dir,filename)
        # print(img_path)        
        image = cv2.imread(img_path)
        dets = detectors(image, 1)
        # print(dets)        
        d = dets[0]
        # print(d)        
        shape = sp(image, d)
        face_descriptor = facerec.compute_face_descriptor(image, shape, 4, 0.25)
        encode.append(face_descriptor)
        name.append(dir)
encode = np.array(encode)
name  = np.array(name)
print(encode)
print(name)
np.save("files_db/endings.npy",encode)
np.save("files_db/name.npy",name)
Recognise the face code


import json
import uuid
import cv2
import dlib
import numpy as np
from datetime import datetime
start_time = datetime.now()

predictor_path = "models/shape_predictor_68_face_landmarks.dat"face_rec_model_path = "models/dlib_face_recognition_resnet_model_v1.dat"detectors = dlib.get_frontal_face_detector()
sp = dlib.shape_predictor(predictor_path)
facerec = dlib.face_recognition_model_v1(face_rec_model_path)
img = cv2.imread("data/Moorthy/Moorthy10.png")
dets = detectors(img, 1)
d = dets[0]
shape = sp(img, d)
face_descriptor = facerec.compute_face_descriptor(img, shape, 4, 0.25)
d_test = np.array(face_descriptor)
data = np.load('files_db/endings.npy')
test = []
for x in data:
    ecludian = np.linalg.norm(d_test-x)
    test.append(ecludian)
names = np.load('files_db/name.npy')
com = dict(zip(test, names))
order = sorted(com.items(),key=lambda d:d[1])
result = min(order)
print(result)
end_time = datetime.now()
print('Duration: {}'.format(end_time - start_time))

4.Arc Face

Reference Link :-Face Recognition with FaceNet and MTCNN 
https://arsfutura.com/magazine/face-recognition-with-facenet-and-mtcnn/

download the code this repository

create a folder as same dlip 

Go to the path of  face recognition folder ->face_features_extractor.py->remove this word(prewhiten=False) line number 10

create pickle model python code


import os
import argparse
import joblib
import numpy as np
from PIL import Image
from torchvision import transforms, datasets
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn import metrics
from face_recognition import preprocessing, FaceFeaturesExtractor, FaceRecogniser
import time

start_time = time.time()
MODEL_DIR_PATH = 'model'def dataset_to_embeddings(dataset, features_extractor):
    transform = transforms.Compose([
        preprocessing.ExifOrientationNormalize(),        transforms.Resize(1024)
    ])

    embeddings = []
    labels = []
    for img_path, label in dataset.samples:
        print(img_path)
        _, embedding = features_extractor(transform(Image.open(img_path).convert('RGB')))
        if embedding is None:
            print("Could not find face on {}".format(img_path))
            continue        if embedding.shape[0] > 1:
            print("Multiple faces detected for {}, taking one with highest probability".format(img_path))
            embedding = embedding[0, :]
        embeddings.append(embedding.flatten())
        labels.append(label)

    return np.stack(embeddings), labels

def load_data(features_extractor):
    dataset = datasets.ImageFolder('Images/')
    # print(dataset)    embeddings, labels = dataset_to_embeddings(dataset, features_extractor)
    # print(embeddings, labels, dataset.class_to_idx)    return embeddings, labels, dataset.class_to_idx

def train(embeddings, labels):
    softmax = LogisticRegression(solver='lbfgs', multi_class='multinomial', C=10, max_iter=10000)
    clf = softmax
    clf.fit(embeddings, labels)
    return clf

def main():
#    features_extractor = FaceFeaturesExtractor()

    embeddings, labels, class_to_idx = load_data(features_extractor)

    clf = train(embeddings, labels)
    print(clf)
#    idx_to_class = {v: k for k, v in class_to_idx.items()}

    target_names = map(lambda i: i[1], sorted(idx_to_class.items(), key=lambda i: i[0]))
    print(metrics.classification_report(labels, clf.predict(embeddings), target_names=list(target_names)))

    if not os.path.isdir(MODEL_DIR_PATH):
        os.mkdir(MODEL_DIR_PATH)
    model_path = os.path.join('model', 'face_recogniser.pkl')
    joblib.dump(FaceRecogniser(features_extractor, clf, idx_to_class), model_path)


if __name__ == '__main__':
    main()

print("time elapsed: {:.2f}s".format(time.time() - start_time))
Recognise the face code


import os
import joblib
import argparse
from PIL import Image
from inference.util import draw_bb_on_img
from inference.constants import MODEL_PATH
from face_recognition import preprocessing

def recognise_faces(img):
    faces = joblib.load(MODEL_PATH)(img)
    if faces:
        draw_bb_on_img(faces, img)
    return faces, img
preprocess = preprocessing.ExifOrientationNormalize()
img = Image.open('Images/Vijay/vijay.jpeg')
filename = img.filename
img = preprocess(img)
img = img.convert('RGB')

faces, img = recognise_faces(img)
print(faces[0][0][1] * 100)
if faces[0][0][1] * 100 >= 80:
    print(faces[0][0][0])
else:
    print("NO")
if not faces:
    print('No faces found in this image.')
